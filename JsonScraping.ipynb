{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMYXkY0Edx406U1I9ycAp3z",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Drmcoelho/Python/blob/main/JsonScraping.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xKYVtNfHH7Yg"
      },
      "outputs": [],
      "source": [
        "\n",
        "#Altere a solução abaixo, criando classes, sub ou super, - cujo intuito não tenha nada a ver geração de html mas em entendê-lo e armaze-lo - com RegEx para criar padrões de tags e estrutura-lós num formato json e não html - vejo como mais adequado para leitura humano-máquina, criando uma array com objetos de arrays ou outra estruturação que mais se adeque a detalhar e discriminar o conteúdo todo da pagina, e outras classes usando como argumentos o que lhes for cabível, de forma modular e usando categorias como texting, media, images, url, links, headings, metadata, etc. sendo que a classe usara métodos para gerar as tags usando RegEx no scraped, mesmo que de início não categorize adequamente mas que organize e agrupe no json os similares mesmo que não interconectos robustando, complexando e sendo sagaz e inteligente ao refatorar o código da resposta:\n",
        "\n",
        "#Para robustecer nosso exemplo de web scraping, especialmente focando na abordagem OOP e na compreensão profunda do back-end e do front-end dos sites, vamos expandir o conceito inicial. A ideia é construir um sistema que não apenas coleta dados mas também analisa a estrutura do site de forma inteligente, utilizando ferramentas de desenvolvedor para criar um HTML personalizado baseado nos dados coletados. Este processo pode ser automatizado para facilitar a criação de conteúdo dinâmico ou relatórios.\n",
        "\n",
        "#Ampliando a Classe WebScraper para Análise Avançada e Geração de HTML\n",
        "#A seguir, vamos imaginar uma versão avançada da nossa classe WebScraper, que inclui métodos para:\n",
        "\n",
        "#Analisar a Estrutura do Site: Utilizando o BeautifulSoup para entender a estrutura do HTML e identificar padrões nos dados que estamos interessados em coletar.\n",
        "#Geração de HTML Personalizado: Com base nos dados coletados e na análise da estrutura do site, gerar um novo HTML que apresente esses dados de forma organizada.\n",
        "\n",
        "from bs4 import BeautifulSoup\n",
        "import requests\n",
        "\n",
        "class WebScraperAvancado:\n",
        "    def __init__(self, url):\n",
        "        self.url = url\n",
        "        self.soup = None\n",
        "\n",
        "    def obter_pagina(self):\n",
        "        resposta = requests.get(self.url)\n",
        "        self.soup = BeautifulSoup(resposta.text, 'html.parser')\n",
        "\n",
        "    def analisar_estrutura(self):\n",
        "        # Este método deveria analisar a estrutura da página e identificar padrões.\n",
        "        # Exemplo: identificar todas as divs que contêm informações de produtos.\n",
        "        estrutura = {\n",
        "            \"produtos\": self.soup.find_all('div', class_='produto')\n",
        "        }\n",
        "        return estrutura\n",
        "\n",
        "    def gerar_html_personalizado(self, dados):\n",
        "        html = \"<html><head><title>Relatório de Produtos</title></head><body>\"\n",
        "        for produto in dados:\n",
        "            html += f\"<div><h2>{produto['nome']}</h2><p>Preço: {produto['preco']}</p><p>Categoria: {produto['categoria']}</p></div>\"\n",
        "        html += \"</body></html>\"\n",
        "        return html\n",
        "\n",
        "    def salvar_html(self, html, arquivo):\n",
        "        with open(arquivo, 'w') as file:\n",
        "            file.write(html)\n",
        "\n",
        "# Exemplo de uso:\n",
        "url = 'http://example.com'  # Substitua pela URL real\n",
        "scraper = WebScraperAvancado(url)\n",
        "scraper.obter_pagina()\n",
        "dados_estruturados = scraper.analisar_estrutura()  # Simulação, implemente conforme necessário\n",
        "html_personalizado = scraper.gerar_html_personalizado(dados_estruturados)\n",
        "scraper.salvar_html(html_personalizado, 'relatorio.html')\n",
        "\n",
        "<p>Para robustecer nosso exemplo de web scraping, especialmente focando na abordagem OOP e na compreensão profunda do back-end e do front-end dos sites, vamos expandir o conceito inicial. A ideia é construir um sistema que não apenas coleta dados mas também analisa a estrutura do site de forma inteligente, utilizando ferramentas de desenvolvedor para criar um HTML personalizado baseado nos dados coletados. Este processo pode ser automatizado para facilitar a criação de conteúdo dinâmico ou relatórios.</p><h3>Ampliando a Classe WebScraper para Análise Avançada e Geração de HTML</h3><p>A seguir, vamos imaginar uma versão avançada da nossa classe <code>WebScraper</code>, que inclui métodos para:</p><ol><li><strong>Analisar a Estrutura do Site</strong>: Utilizando o BeautifulSoup para entender a estrutura do HTML e identificar padrões nos dados que estamos interessados em coletar.</li><li><strong>Geração de HTML Personalizado</strong>: Com base nos dados coletados e na análise da estrutura do site, gerar um novo HTML que apresente esses dados de forma organizada.</li></ol><pre><div class=\"dark bg-gray-950 rounded-md\"><div class=\"flex items-center relative text-token-text-secondary bg-token-main-surface-secondary px-4 py-2 text-xs font-sans justify-between rounded-t-md\"><span>python</span><span class=\"\" data-state=\"closed\"><button class=\"flex gap-1 items-center\"><svg width=\"24\" height=\"24\" viewBox=\"0 0 24 24\" fill=\"none\" xmlns=\"http://www.w3.org/2000/svg\" class=\"icon-sm\"><path fill-rule=\"evenodd\" clip-rule=\"evenodd\" d=\"M12 3.5C10.8954 3.5 10 4.39543 10 5.5H14C14 4.39543 13.1046 3.5 12 3.5ZM8.53513 3.5C9.22675 2.3044 10.5194 1.5 12 1.5C13.4806 1.5 14.7733 2.3044 15.4649 3.5H17.25C18.9069 3.5 20.25 4.84315 20.25 6.5V18.5C20.25 20.1569 19.1569 21.5 17.25 21.5H6.75C5.09315 21.5 3.75 20.1569 3.75 18.5V6.5C3.75 4.84315 5.09315 3.5 6.75 3.5H8.53513ZM8 5.5H6.75C6.19772 5.5 5.75 5.94772 5.75 6.5V18.5C5.75 19.0523 6.19772 19.5 6.75 19.5H17.25C18.0523 19.5 18.25 19.0523 18.25 18.5V6.5C18.25 5.94772 17.8023 5.5 17.25 5.5H16C16 6.60457 15.1046 7.5 14 7.5H10C8.89543 7.5 8 6.60457 8 5.5Z\" fill=\"currentColor\"></path></svg>Copy code</button></span></div><div class=\"p-4 overflow-y-auto\"><code class=\"!whitespace-pre hljs language-python\"><span class=\"hljs-keyword\">from</span> bs4 <span class=\"hljs-keyword\">import</span> BeautifulSoup\n",
        "<span class=\"hljs-keyword\">import</span> requests\n",
        "\n",
        "<span class=\"hljs-keyword\">class</span> <span class=\"hljs-title class_\">WebScraperAvancado</span>:\n",
        "    <span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">__init__</span>(<span class=\"hljs-params\">self, url</span>):\n",
        "        self.url = url\n",
        "        self.soup = <span class=\"hljs-literal\">None</span>\n",
        "\n",
        "    <span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">obter_pagina</span>(<span class=\"hljs-params\">self</span>):\n",
        "        resposta = requests.get(self.url)\n",
        "        self.soup = BeautifulSoup(resposta.text, <span class=\"hljs-string\">'html.parser'</span>)\n",
        "\n",
        "    <span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">analisar_estrutura</span>(<span class=\"hljs-params\">self</span>):\n",
        "        <span class=\"hljs-comment\"># Este método deveria analisar a estrutura da página e identificar padrões.</span>\n",
        "        <span class=\"hljs-comment\"># Exemplo: identificar todas as divs que contêm informações de produtos.</span>\n",
        "        estrutura = {\n",
        "            <span class=\"hljs-string\">\"produtos\"</span>: self.soup.find_all(<span class=\"hljs-string\">'div'</span>, class_=<span class=\"hljs-string\">'produto'</span>)\n",
        "        }\n",
        "        <span class=\"hljs-keyword\">return</span> estrutura\n",
        "\n",
        "    <span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">gerar_html_personalizado</span>(<span class=\"hljs-params\">self, dados</span>):\n",
        "        html = <span class=\"hljs-string\">\"&lt;html&gt;&lt;head&gt;&lt;title&gt;Relatório de Produtos&lt;/title&gt;&lt;/head&gt;&lt;body&gt;\"</span>\n",
        "        <span class=\"hljs-keyword\">for</span> produto <span class=\"hljs-keyword\">in</span> dados:\n",
        "            html += <span class=\"hljs-string\">f\"&lt;div&gt;&lt;h2&gt;<span class=\"hljs-subst\">{produto[<span class=\"hljs-string\">'nome'</span>]}</span>&lt;/h2&gt;&lt;p&gt;Preço: <span class=\"hljs-subst\">{produto[<span class=\"hljs-string\">'preco'</span>]}</span>&lt;/p&gt;&lt;p&gt;Categoria: <span class=\"hljs-subst\">{produto[<span class=\"hljs-string\">'categoria'</span>]}</span>&lt;/p&gt;&lt;/div&gt;\"</span>\n",
        "        html += <span class=\"hljs-string\">\"&lt;/body&gt;&lt;/html&gt;\"</span>\n",
        "        <span class=\"hljs-keyword\">return</span> html\n",
        "\n",
        "    <span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">salvar_html</span>(<span class=\"hljs-params\">self, html, arquivo</span>):\n",
        "        <span class=\"hljs-keyword\">with</span> <span class=\"hljs-built_in\">open</span>(arquivo, <span class=\"hljs-string\">'w'</span>) <span class=\"hljs-keyword\">as</span> file:\n",
        "            file.write(html)\n",
        "\n",
        "<span class=\"hljs-comment\"># Exemplo de uso:</span>\n",
        "url = <span class=\"hljs-string\">'http://example.com'</span>  <span class=\"hljs-comment\"># Substitua pela URL real</span>\n",
        "scraper = WebScraperAvancado(url)\n",
        "scraper.obter_pagina()\n",
        "dados_estruturados = scraper.analisar_estrutura()  <span class=\"hljs-comment\"># Simulação, implemente conforme necessário</span>\n",
        "html_personalizado = scraper.gerar_html_personalizado(dados_estruturados)\n",
        "scraper.salvar_html(html_personalizado, <span class=\"hljs-string\">'relatorio.html'</span>)\n",
        "</code></div></div></pre><p></p>\n",
        "\n",
        "\n",
        "    from bs4 import BeautifulSoup\n",
        "    import requests\n",
        "\n",
        "    class WebScraperAvancado:\n",
        "        def __init__(self, url):\n",
        "            self.url = url\n",
        "            self.soup = None\n",
        "\n",
        "        def obter_pagina(self):\n",
        "            resposta = requests.get(self.url)\n",
        "            self.soup = BeautifulSoup(resposta.text, 'html.parser')\n",
        "\n",
        "        def analisar_estrutura(self):\n",
        "            # Este método deveria analisar a estrutura da página e identificar padrões.\n",
        "            # Exemplo: identificar todas as divs que contêm informações de produtos.\n",
        "            estrutura = {\n",
        "                \"produtos\": self.soup.find_all('div', class_='produto')\n",
        "            }\n",
        "            return estrutura\n",
        "\n",
        "        def gerar_html_personalizado(self, dados):\n",
        "            html = \"<html><head><title>Relatório de Produtos</title></head><body>\"\n",
        "            for produto in dados:\n",
        "                html += f\"<div><h2>{produto['nome']}</h2><p>Preço: {produto['preco']}</p><p>Categoria: {produto['categoria']}</p></div>\"\n",
        "            html += \"</body></html>\"\n",
        "            return html\n",
        "\n",
        "        def salvar_html(self, html, arquivo):\n",
        "            with open(arquivo, 'w') as file:\n",
        "                file.write(html)\n",
        "\n",
        "    # Exemplo de uso:\n",
        "    url = 'http://example.com'  # Substitua pela URL real\n",
        "    scraper = WebScraperAvancado(url)\n",
        "    scraper.obter_pagina()\n",
        "    dados_estruturados = scraper.analisar_estrutura()  # Simulação, implemente conforme necessário\n",
        "    html_personalizado = scraper.gerar_html_personalizado(dados_estruturados)\n",
        "    scraper.salvar_html(html_personalizado, 'relatorio.html')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "42Os26p2ImMi"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}